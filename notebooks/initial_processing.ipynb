{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import csv\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import sys\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #File Handling\n",
    "# if sys.platform==('win32'):\n",
    "#     os.chdir('\\\\')\n",
    "#     print(os.getcwd())\n",
    "os.chdir('C:\\\\Users\\Patrick\\Documents\\programs\\sensory-restricted-analysis')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "pathname = r\"C:\\Users\\Patrick\\Datasets\\sr\\SR\"\n",
    "time_path = pathname + r\"\\1.Data\\20180305.1\\20180305.1.2\\GCaMP_Time_Pre.csv\"\n",
    "gcamp_data_path = pathname + r'\\1.Data\\20180305.1\\20180305.1.2\\ROI-profiles.txt'\n",
    "kinematic_data_path = pathname + r'\\1.Data\\20180305.1\\20180305.1.2\\20180305_Fly1_THDDC_SR_2.dat'\n",
    "start_stop_data_path = pathname + r'\\1.Data2\\20180305.1\\20180305.1.2\\1.Traces\\StopStart_Times_Exact.csv'\n",
    "light_times_path = pathname + r'\\1.Data\\20180305.1\\20180305.1.2\\Light_Times.xlsx'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open(time_path, 'r')\n",
    "times = [float(i) for i in (f.read().split(','))]\n",
    "GCaMP_Time = np.asarray(times)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(gcamp_data_path, header=None)\n",
    "FicTracData = np.genfromtxt(kinematic_data_path, delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_trans = df.T\n",
    "tag = df_trans.iloc[0][0]\n",
    "header = df_trans.iloc[1]\n",
    "for idx, item in enumerate(header):\n",
    "    if idx < 8:\n",
    "        header[idx] = item.strip() + '_red'\n",
    "    else:\n",
    "        header[idx] = item.strip() + '_green'\n",
    "    \n",
    "df_trans.drop(axis=0, index=[0,1], inplace=True)\n",
    "\n",
    "df_trans = df_trans.reset_index(drop=True)\n",
    "df_trans.columns=header.T\n",
    "df_trans['time'] = pd.Series(times)\n",
    "GCamp_data = df_trans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Metadata(object):\n",
    "\n",
    "    def __init__(self, year, month, day, fly_no, THDDC, SR):\n",
    "        self.day = day\n",
    "        self.month = month\n",
    "        self.year = year\n",
    "        self.fly_no = fly_no\n",
    "        self.THDDC = THDDC\n",
    "        self.SR = SR\n",
    "\n",
    "def metadata_assigner(tag):\n",
    "    splits = tag.split('_')\n",
    "    year = splits[0][3:7]\n",
    "    month = splits[0][7:9]\n",
    "    day = splits[0][9:11]\n",
    "    fly_no = splits[1][-1]\n",
    "    if splits[2]=='THDDC':\n",
    "        THDDC = True\n",
    "    else:\n",
    "        THDDC = False\n",
    "    if splits[3] == 'SR':\n",
    "        SR = True\n",
    "    else:\n",
    "        SR = False\n",
    "        \n",
    "    metadata_blob = Metadata(year, month, day, fly_no, THDDC, SR)\n",
    "    return metadata_blob\n",
    "#USE: new_metadata = metadata_assigner(tag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ported from Ari Matlab Code \"scrap_test.m\"\n",
    "\n",
    "#Why -9 -----------------------------------------------------------------------<\n",
    "GCamp_Time = GCamp_Time_Pre - GCamp_Time_Pre[0]\n",
    "Trace_Length = GCamp_Time[-1-9]\n",
    "\n",
    "xpos_pre=FicTracData[:,14]\n",
    "ypos_pre=FicTracData[:,15]\n",
    "Roll_Pre=FicTracData[:,5]\n",
    "Pitch_Pre=FicTracData[:,6]\n",
    "Ang_Pre=FicTracData[:,7]\n",
    "Heading_Pre=FicTracData[:,16]\n",
    "Frames_Pre=FicTracData[:,0].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Patrick\\Anaconda3\\lib\\site-packages\\openpyxl\\reader\\worksheet.py:318: UserWarning: Unknown extension is not supported and will be removed\n",
      "  warn(msg)\n"
     ]
    }
   ],
   "source": [
    "#Normalize heading between pi and negative pi\n",
    "pi = 3.14159\n",
    "Heading1=((Heading_Pre+pi)%(2*pi))-pi;\n",
    "\n",
    "#Import The time that the light turns on            \n",
    "import openpyxl\n",
    "wb=openpyxl.load_workbook(light_times_path)\n",
    "\n",
    "sheet = wb['Sheet1']\n",
    "Lights_On_1 = sheet['A1'].value - 1\n",
    "Lights_On_2 = sheet['A2'].value - 1\n",
    "\n",
    "#Get Proper Index for start and stop\n",
    "Start_frame=np.where(Frames_Pre==Lights_On_1)[0][0]\n",
    "End_frame=np.where(Frames_Pre==Lights_On_2)[0][0]\n",
    "\n",
    "# Cut motion data appropriately\n",
    "Roll=Roll_Pre[Start_frame:End_frame]\n",
    "Pitch=Pitch_Pre[Start_frame:End_frame]\n",
    "Ang=Ang_Pre[Start_frame:End_frame]\n",
    "Heading=Heading1[Start_frame:End_frame]\n",
    "Frames=Frames_Pre[Start_frame:End_frame]\n",
    "RATE=(Frames[-1]-Frames[0])/Trace_Length\n",
    "FicTrac_Time_Real1=Frames*(1/RATE)\n",
    "FicTrac_Time_Real=FicTrac_Time_Real1-FicTrac_Time_Real1[0]\n",
    "xpos_PRE=xpos_pre[Start_frame:End_frame]\n",
    "ypos_PRE=ypos_pre[Start_frame:End_frame]\n",
    "xpos=xpos_PRE-xpos_PRE[0];\n",
    "ypos=ypos_PRE-ypos_PRE[0];\n",
    "\n",
    "#Combine Roll, Pitch, and Ang to create Motion\n",
    "Motion = np.linalg.norm([Pitch, Ang, Roll], axis=0)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CIRF_conv(timeseries):       \n",
    "    # ---------------------------------------------------------------------\n",
    "    # INPUT: Time series kinematic data from experimental data collection, dim([1,N])\n",
    "    # RETURNS: Time series convolved with CIRF Function\n",
    "    # ---------------------------------------------------------------------\n",
    "    CIRF = -1*(np.power(2, (-FicTrac_Time_Real/0.175)) - np.power(2, (-FicTrac_Time_Real/0.55)))\n",
    "    ts = timeseries\n",
    "    #Pad the ts Data\n",
    "    ts_Padded_Front = np.append((np.zeros((1,ts.shape[0]),dtype='float64')), (np.transpose(ts)))\n",
    "    ts_Padded = np.append(ts_Padded_Front, (np.zeros((1,ts.shape[0]),dtype='float64')))\n",
    "    #Convolution\n",
    "    ts_Conv_Padded=np.convolve(ts_Padded, CIRF)\n",
    "    #UnPad\n",
    "    ts_Conv=ts_Conv_Padded[(ts.shape[0]+1):(ts.shape[0]*2)]\n",
    "    return ts_Conv\n",
    "\n",
    "Ang_Conv = CIRF_conv(Ang)\n",
    "Pitch_Conv = CIRF_conv(Pitch)\n",
    "Roll_Conv = CIRF_conv(Roll)\n",
    "Motion_Conv = CIRF_conv(Motion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "G2_R=GCamp_data['G2R_green']/GCamp_data['G2R_red']\n",
    "G3_R=GCamp_data['G3R_green']/GCamp_data['G3R_red']\n",
    "G4_R=GCamp_data['G4R_green']/GCamp_data['G4R_red']\n",
    "G5_R=GCamp_data['G5R_green']/GCamp_data['G5R_red']\n",
    "\n",
    "G2_L=GCamp_data['G2L_green']/GCamp_data['G2L_red']\n",
    "G3_L=GCamp_data['G3L_green']/GCamp_data['G3L_red']\n",
    "G4_L=GCamp_data['G4L_green']/GCamp_data['G4L_red']\n",
    "G5_L=GCamp_data['G5L_green']/GCamp_data['G5L_red']\n",
    "\n",
    "G2_AVG= np.mean(np.concatenate((G2_L, G2_R), axis=0))\n",
    "G3_AVG=np.mean(np.concatenate((G3_L, G3_R),axis=0))\n",
    "G4_AVG=np.mean(np.concatenate((G4_L, G4_R),axis=0))\n",
    "G5_AVG=np.mean(np.concatenate((G5_L, G5_R),axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = G3_R.values\n",
    "x = np.linspace(0,18246, num = 3030)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_times = pd.read_csv(start_stop_data_path, header=None).values[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "Time1 = start_times\n",
    "\n",
    "if (Time1<295) and (Time1>6):\n",
    "    \n",
    "    Time1_F_Diff = np.absolute(FicTrac_Time_Real-Time1)\n",
    "    Frame1_F = np.where(Time1_F_Diff==(np.amin(Time1_F_Diff)))[0][0]\n",
    "    \n",
    "    Time1_G_Diff = np.absolute(GCaMP_Time-Time1)\n",
    "    Frame1_G=np.where(Time1_G_Diff==(np.amin(Time1_G_Diff)))[0][0]\n",
    "    \n",
    "    Time_F_Bout=FicTrac_Time_Real[(Frame1_F-300):(Frame1_F+300)];\n",
    "    Time_G_Bout=GCaMP_Time[(Frame1_G-50):(Frame1_G+50)];\n",
    "\n",
    "#Avg the Motion data leading up to each timepoint when GCaMP capture occured\n",
    "    Motion_Bout_Avg=[]\n",
    "    for i in range(Time_G_Bout.shape[0]):\n",
    "        T = Time_G_Bout[i]\n",
    "        Time_Diff=np.absolute(FicTrac_Time_Real-T)\n",
    "        Minimum=np.amin(Time_Diff)\n",
    "        INDEX=np.where(Time_Diff==(np.amin(Time_Diff)))[0][0]\n",
    "        Motion_Bout_Avg.append((np.sum(Motion_Conv[(INDEX-2):INDEX+2]))/5)\n",
    "\n",
    "\n",
    "    Motion_Bout=Motion_Bout_Avg\n",
    "    G2_Bout=G2_R[(Frame1_G-50):(Frame1_G+50)].values\n",
    "    G3_Bout=G3_R[(Frame1_G-50):(Frame1_G+50)].values\n",
    "    G4_Bout=G4_R[(Frame1_G-50):(Frame1_G+50)].values\n",
    "    G5_Bout=G5_R[(Frame1_G-50):(Frame1_G+50)].values\n",
    "\n",
    "    G2_Corr = []\n",
    "    G3_Corr = []\n",
    "    G4_Corr = []\n",
    "    G5_Corr = []\n",
    "    \n",
    "    from scipy.stats import pearsonr\n",
    "    \n",
    "    G2_Corr_pre = pearsonr(Motion_Bout[46:66],G2_Bout[46:66])\n",
    "    G2_Corr.append(G2_Corr_pre[0])\n",
    "    \n",
    "    G3_Corr_pre = pearsonr(Motion_Bout[46:66],G3_Bout[46:66])\n",
    "    G3_Corr.append(G3_Corr_pre[0])\n",
    "    \n",
    "    G4_Corr_pre = pearsonr(Motion_Bout[46:66],G4_Bout[46:66])\n",
    "    G4_Corr.append(G4_Corr_pre[0])\n",
    "    \n",
    "    G5_Corr_pre = pearsonr(Motion_Bout[46:66],G5_Bout[46:66])\n",
    "    G5_Corr.append(G5_Corr_pre[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
