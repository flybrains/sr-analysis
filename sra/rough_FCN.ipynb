{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import data_load as dl\n",
    "import models\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# from keras.models import Model\n",
    "# from keras.layers import Input, Conv2D, ZeroPadding1D, Conv2DTranspose, UpSampling2D, Dense, BatchNormalization\n",
    "# from keras.layers.pooling import MaxPooling2D, MaxPooling1D\n",
    "from keras import optimizers\n",
    "# import sklearn\n",
    "# import tensorflow as tf\n",
    "\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Patrick\\Anaconda3\\lib\\site-packages\\openpyxl\\reader\\worksheet.py:318: UserWarning: Unknown extension is not supported and will be removed\n",
      "  warn(msg)\n"
     ]
    }
   ],
   "source": [
    "path = r\"C:\\Users\\Patrick\\Datasets\\sr\\SR\"\n",
    "trial_paths = dl.combine_data(path)\n",
    "trials = dl.generate_trial_objects(trial_paths)\n",
    "processed_trials = dl.process_trial_data(trials)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Smallest motion sample is 17559\n",
    "# All G samples are 3030 long\n",
    "# Take 2880 points from middle of 3030\n",
    "# 3030 - 2880 = 150\n",
    "#150/2 = 75\n",
    "#Start each (Gs and downsampled motion on point 75) then sample out 2880"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def synch_streams(G2, G3, G4, G5, motion):\n",
    "    G2 = G2[75:-75]\n",
    "    G3 = G3[75:-75]\n",
    "    G4 = G4[75:-75]\n",
    "    G5 = G5[75:-75]\n",
    "    \n",
    "    new_motion = motion[0:-1:6]\n",
    "    new_motion = motion[75:(75+2880)]\n",
    "    \n",
    "    return G2, G3, G4, G5, new_motion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_segments(G2, G3, G4, G5, motion):\n",
    "    full_run_length = 2880\n",
    "    num_segments = 400\n",
    "    indices = np.random.randint(0,(full_run_length - 112), size=(num_segments))\n",
    "    \n",
    "    images_out = []\n",
    "    motion_out = []\n",
    "    \n",
    "    for i in indices:\n",
    "        G2_seg = G2[i:(i+112)]\n",
    "        G3_seg = G3[i:(i+112)]\n",
    "        G4_seg = G4[i:(i+112)]\n",
    "        G5_seg = G5[i:(i+112)]\n",
    "        motion_seg = motion[i:(i+112):2]\n",
    "        \n",
    "        new_image = np.array([[G2_seg],[G3_seg],[G4_seg],[G5_seg]])\n",
    "        \n",
    "        images_out.append(new_image)\n",
    "        \n",
    "        motion_out.append(np.asarray(motion_seg))\n",
    "        \n",
    "    return images_out, motion_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = []\n",
    "y = []\n",
    "\n",
    "for i in range(25):\n",
    "    trial = processed_trials[i]\n",
    "    G2_temp, G3_temp, G4_temp, G5_temp, motion_temp = synch_streams(trial.G2_AVG, trial.G3_AVG, trial.G4_AVG, trial.G5_AVG, trial.Motion_Conv)\n",
    "    images, motion = generate_segments(G2_temp, G3_temp, G4_temp, G5_temp, motion_temp)\n",
    "    \n",
    "    for image in images:\n",
    "        new_image=np.array(image)\n",
    "        new_image.reshape(1,112,4)\n",
    "        X.append(new_image)\n",
    "    \n",
    "    for entry in motion:\n",
    "        y.append(np.array(entry))\n",
    "        \n",
    "X = np.array(X).reshape(10000,1,112,4)\n",
    "y = np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trial = processed_trials[5]\n",
    "# G3_temp, G4_temp, motion_temp = synch_streams(trial.G3_AVG, trial.G4_AVG, trial.Motion_Conv)\n",
    "# images, motion = generate_segments(G3_temp, G4_temp, motion_temp)\n",
    "\n",
    "# X = []\n",
    "# y = []\n",
    "\n",
    "# for image in images:\n",
    "#     new_image=np.array(image)\n",
    "#     new_image.reshape(1,112,2)\n",
    "#     X.append(new_image)\n",
    "    \n",
    "# for entry in motion:\n",
    "#     y.append(np.array(entry))\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 1, 112, 4)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 56)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X = np.expand_dims(X, axis=2)\n",
    "#X = np.expand_dims(X, axis=3)\n",
    "\n",
    "y = np.expand_dims(y, axis=1)\n",
    "y.reshape(10000,1,56)\n",
    "y = np.expand_dims(y, axis=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 1, 112, 4)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 1, 56, 1)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X/(np.max(abs(X)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inputs = Input(shape=(1,112,4), name=\"main_input\")\n",
    "\n",
    "# x1 = Conv2D(8, kernel_size=(1,3), padding=\"same\")(inputs)\n",
    "# x1 = MaxPooling2D(pool_size=(1,2), strides=(2))(x1)\n",
    "# x1 = BatchNormalization(axis=1, momentum=0.99, epsilon=0.001, center=True, scale=True)(x1)\n",
    "\n",
    "# x2 = Conv2D(16, kernel_size=(1,3),padding=\"same\")(x1)\n",
    "# x2 = MaxPooling2D(pool_size=(1,2), strides=(2))(x2)\n",
    "# x2 = BatchNormalization(axis=1, momentum=0.99, epsilon=0.001, center=True, scale=True)(x2)\n",
    "\n",
    "# x3 = Conv2D(32, kernel_size=(1,3),padding=\"same\")(x2)\n",
    "# x3 = MaxPooling2D(pool_size=(1,2), strides=(2))(x3)\n",
    "# x3 = BatchNormalization(axis=1, momentum=0.99, epsilon=0.001, center=True, scale=True)(x3)\n",
    "\n",
    "# x4 = Conv2D(64, kernel_size=(1,3),padding=\"same\")(x3)\n",
    "# x4 = MaxPooling2D(pool_size=(1,2), strides=(2))(x4)\n",
    "# x4 = BatchNormalization(axis=1, momentum=0.99, epsilon=0.001, center=True, scale=True)(x4)\n",
    "\n",
    "# x5 = Conv2D(128, kernel_size=(1,7))(x4)\n",
    "\n",
    "# x6 = Dense(128)(x5)\n",
    "\n",
    "# #Presently doing unpooling in hacked way (No filtering for max value, naive upsampling)\n",
    "# # https://arxiv.org/pdf/1311.2901v3.pdf\n",
    "# # https://stackoverflow.com/questions/44991470/using-tensorflow-layers-in-keras\n",
    "\n",
    "# #Need to create custom keras layer to take mask from MaxPooling2D (similar to TF's max_pool_with_argmax)\n",
    "# #mask is used in unpooling layer\n",
    "\n",
    "# x7 = Conv2DTranspose(128, kernel_size=(1,7), padding='valid')(x6)\n",
    "# x7 = UpSampling2D((1,2))(x7)\n",
    "# x7 = BatchNormalization(axis=1, momentum=0.99, epsilon=0.001, center=True, scale=True)(x7)\n",
    "\n",
    "# x8 = Conv2DTranspose(64, kernel_size=(1,3), padding='same')(x7)\n",
    "# x8 = UpSampling2D((1,2))(x8)\n",
    "# x8 = BatchNormalization(axis=1, momentum=0.99, epsilon=0.001, center=True, scale=True)(x8)\n",
    "\n",
    "# x9 = Conv2DTranspose(32, kernel_size=(1,3), padding='same')(x8)\n",
    "# x9 = UpSampling2D((1,2))(x9)\n",
    "# x9 = BatchNormalization(axis=1, momentum=0.99, epsilon=0.001, center=True, scale=True)(x9)\n",
    "\n",
    "# x10 = Conv2DTranspose(16, kernel_size=(1,3), padding='same')(x9)\n",
    "# x10 = BatchNormalization(axis=1, momentum=0.99, epsilon=0.001, center=True, scale=True)(x10)\n",
    "\n",
    "# x11 = Conv2DTranspose(4, kernel_size=(1,3), padding='same')(x10)\n",
    "# x11 = BatchNormalization(axis=1, momentum=0.99, epsilon=0.001, center=True, scale=True)(x11)\n",
    "\n",
    "# x11 = Conv2DTranspose(2, kernel_size=(1,3), padding='same')(x11)\n",
    "# x11 = Conv2DTranspose(1, kernel_size=(1,3), padding='same')(x11)\n",
    "# x12 = BatchNormalization(axis=1, momentum=0.99, epsilon=0.001, center=True, scale=True)(x11)\n",
    "\n",
    "# model2 = Model(inputs=inputs, outputs=x12)\n",
    "\n",
    "# sgd = optimizers.SGD(lr=0.01, momentum=0.9, decay=0.0005)\n",
    "\n",
    "# model2.compile(optimizer=sgd, loss = 'mean_squared_error', metrics = ['mse'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = models.FCN(4,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in model2.layers:\n",
    "    print(layer.output_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_small = X[0:100]\n",
    "y_small = y[0:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2.fit(X_small, y_small, epochs=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testno = 99\n",
    "testX = np.expand_dims(X[testno],0)\n",
    "testy = np.squeeze(y[testno])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model2.predict(testX)\n",
    "p = np.squeeze(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(testy)\n",
    "plt.plot(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['C:\\\\Users\\\\Patrick\\\\Datasets\\\\sr\\\\SR\\\\1.Data\\\\20180220.3\\\\20180220.3.3',\n",
       " 'C:\\\\Users\\\\Patrick\\\\Datasets\\\\sr\\\\SR\\\\1.Data2\\\\20180220.3\\\\20180220.3.3\\\\1.Traces']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trial_paths[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
