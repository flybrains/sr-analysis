{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [],
   "source": [
    "import data_load as dl\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Conv2D, ZeroPadding1D, Conv2DTranspose, UpSampling2D, Dense\n",
    "from keras.layers.pooling import MaxPooling2D, MaxPooling1D\n",
    "from keras import optimizers\n",
    "import sklearn\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Patrick\\Anaconda3\\lib\\site-packages\\openpyxl\\reader\\worksheet.py:318: UserWarning: Unknown extension is not supported and will be removed\n",
      "  warn(msg)\n"
     ]
    }
   ],
   "source": [
    "path = r\"C:\\Users\\Patrick\\Datasets\\sr\\SR\"\n",
    "trial_paths = dl.combine_data(path)\n",
    "trials = dl.generate_trial_objects(trial_paths)\n",
    "processed_trials = dl.process_trial_data(trials)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Smallest motion sample is 17559\n",
    "# All G samples are 3030 long\n",
    "# Take 2880 points from middle of 3030\n",
    "# 3030 - 2880 = 150\n",
    "#150/2 = 75\n",
    "#Start each (Gs and downsampled motion on point 75) then sample out 2880"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [],
   "source": [
    "def synch_streams(G3, G4, motion):\n",
    "    #G2 = G2[75:-75]\n",
    "    G3 = G3[75:-75]\n",
    "    G4 = G4[75:-75]\n",
    "    #G5 = G5[75:-75]\n",
    "    \n",
    "    new_motion = motion[0:-1:6]\n",
    "    new_motion = motion[75:(75+2880)]\n",
    "    \n",
    "    return G3, G4, new_motion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_segments(G3, G4, motion):\n",
    "    full_run_length = 2880\n",
    "    num_segments = 200\n",
    "    indices = np.random.randint(0,(full_run_length - 112), size=(num_segments))\n",
    "    \n",
    "    images_out = []\n",
    "    motion_out = []\n",
    "    \n",
    "    for i in indices:\n",
    "        #G2_seg = G2[i:(i+112)]/np.amax(G2[i:(i+112)])\n",
    "        G3_seg = G3[i:(i+112)]/np.amax(G3[i:(i+112)])\n",
    "        G4_seg = G4[i:(i+112)]/np.amax(G4[i:(i+112)])\n",
    "        #G5_seg = G5[i:(i+112)]/np.amax(G5[i:(i+112)])\n",
    "        motion_seg = motion[i:(i+112)]/np.amax(motion[i:(i+112)])\n",
    "        \n",
    "        new_image = np.array([[G3_seg],[G4_seg]])\n",
    "        \n",
    "        images_out.append(new_image)\n",
    "        \n",
    "        motion_out.append(np.asarray(motion_seg))\n",
    "        \n",
    "    \n",
    "\n",
    "    return images_out, motion_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = []\n",
    "y = []\n",
    "\n",
    "for i in range(25):\n",
    "    trial = processed_trials[i]\n",
    "    G3_temp, G4_temp, motion_temp = synch_streams(trial.G3_AVG, trial.G4_AVG, trial.Motion_Conv)\n",
    "    images, motion = generate_segments(G3_temp, G4_temp, motion_temp)\n",
    "    \n",
    "    for image in images:\n",
    "        new_image=np.array(image)\n",
    "        new_image.reshape(1,112,2)\n",
    "        X.append(new_image)\n",
    "    \n",
    "    for entry in motion:\n",
    "        y.append(np.array(entry))\n",
    "        \n",
    "X = np.array(X).reshape(5000,1,112,2)\n",
    "y = np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trial = processed_trials[5]\n",
    "# G3_temp, G4_temp, motion_temp = synch_streams(trial.G3_AVG, trial.G4_AVG, trial.Motion_Conv)\n",
    "# images, motion = generate_segments(G3_temp, G4_temp, motion_temp)\n",
    "\n",
    "# X = []\n",
    "# y = []\n",
    "\n",
    "# for image in images:\n",
    "#     new_image=np.array(image)\n",
    "#     new_image.reshape(1,112,2)\n",
    "#     X.append(new_image)\n",
    "    \n",
    "# for entry in motion:\n",
    "#     y.append(np.array(entry))\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5000, 1, 112, 2)"
      ]
     },
     "execution_count": 289,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5000, 112)"
      ]
     },
     "execution_count": 290,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X = np.expand_dims(X, axis=2)\n",
    "#X = np.expand_dims(X, axis=3)\n",
    "\n",
    "y = np.expand_dims(y, axis=1)\n",
    "y.reshape(5000,1,112)\n",
    "y = np.expand_dims(y, axis=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5000, 1, 112, 2)"
      ]
     },
     "execution_count": 292,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5000, 1, 112, 1)"
      ]
     },
     "execution_count": 293,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# model = Sequential()\n",
    "# model.add(Conv2D(64, (2,2), padding='same', activation='relu', input_shape=(100,1,2)))\n",
    "# #model.add(MaxPooling2D(2))\n",
    "\n",
    "# # model.add(Conv2D(24, (2,2), padding='same', activation='relu'))\n",
    "# # model.add(MaxPooling2D(1,2))\n",
    "\n",
    "# # model.add(Conv2DTranspose(1, (1,1), strides=(1,1), activation='relu'))\n",
    "# # model.add(UpSampling2D(size=(1,2)))\n",
    "\n",
    "# #model.add(Conv2DTranspose(1, (1,1), strides=(1,1), activation='relu'))\n",
    "# #model.add(UpSampling2D(size=(2,1)))\n",
    "\n",
    "\n",
    "# model.compile(optimizer='adam', loss = 'mean_squared_error', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = Input(shape=(1,112,2), name=\"main_input\")\n",
    "\n",
    "x1 = Conv2D(64, kernel_size=(1,3), padding=\"same\")(inputs)\n",
    "x1 = Conv2D(64, kernel_size=(1,3),padding=\"same\")(x1)\n",
    "x1 = MaxPooling2D(pool_size=(1,2), strides=(2))(x1)\n",
    "\n",
    "x2 = Conv2D(128, kernel_size=(1,3),padding=\"same\")(x1)\n",
    "x2 = Conv2D(128, kernel_size=(1,3),padding=\"same\")(x2)\n",
    "x2 = MaxPooling2D(pool_size=(1,2), strides=(2))(x2)\n",
    "\n",
    "x3 = Conv2D(256, kernel_size=(1,3),padding=\"same\")(x2)\n",
    "x3 = Conv2D(256, kernel_size=(1,3),padding=\"same\")(x3)\n",
    "x3 = MaxPooling2D(pool_size=(1,2), strides=(2))(x3)\n",
    "\n",
    "x4 = Conv2D(512, kernel_size=(1,3),padding=\"same\")(x3)\n",
    "x4 = Conv2D(512, kernel_size=(1,3),padding=\"same\")(x4)\n",
    "x4 = MaxPooling2D(pool_size=(1,2), strides=(2))(x4)\n",
    "\n",
    "x5 = Conv2D(1024, kernel_size=(1,7))(x4)\n",
    "\n",
    "x6 = Dense(1024)(x5)\n",
    "\n",
    "#Presently doing unpooling in hacked way (No filtering for max value, naive upsampling)\n",
    "# https://arxiv.org/pdf/1311.2901v3.pdf\n",
    "# https://stackoverflow.com/questions/44991470/using-tensorflow-layers-in-keras\n",
    "\n",
    "#Need to create custom keras layer to take mask from MaxPooling2D (similar to TF's max_pool_with_argmax)\n",
    "#mask is used in unpooling layer\n",
    "\n",
    "x7 = Conv2DTranspose(512, kernel_size=(1,7), padding='valid')(x6)\n",
    "x7 = UpSampling2D((1,2))(x7)\n",
    "\n",
    "x8 = Conv2DTranspose(512, kernel_size=(1,3), padding='same')(x7)\n",
    "x8 = Conv2DTranspose(512, kernel_size=(1,3), padding='same')(x8)\n",
    "x8 = UpSampling2D((1,2))(x8)\n",
    "\n",
    "x9 = Conv2DTranspose(512, kernel_size=(1,3), padding='same')(x8)\n",
    "x9 = Conv2DTranspose(256, kernel_size=(1,3), padding='same')(x9)\n",
    "x9 = UpSampling2D((1,2))(x9)\n",
    "\n",
    "x10 = Conv2DTranspose(256, kernel_size=(1,3), padding='same')(x9)\n",
    "x10 = Conv2DTranspose(128, kernel_size=(1,3), padding='same')(x10)\n",
    "x10 = UpSampling2D((1,2))(x10)\n",
    "\n",
    "x11 = Conv2DTranspose(128, kernel_size=(1,3), padding='same')(x10)\n",
    "x11 = Conv2DTranspose(64, kernel_size=(1,3), padding='same')(x11)\n",
    "\n",
    "x11 = Conv2DTranspose(2, kernel_size=(1,3), padding='same')(x11)\n",
    "x12 = Conv2DTranspose(1, kernel_size=(1,3), padding='same')(x11)\n",
    "\n",
    "model2 = Model(inputs=inputs, outputs=x12)\n",
    "\n",
    "sgd = optimizers.SGD(lr=0.01, momentum=0.9, decay=0.0005)\n",
    "\n",
    "model2.compile(optimizer=sgd, loss = 'mean_squared_error', metrics = ['mse'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model1.fit(X,y, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"X.npy\",X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"y.npy\",y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
